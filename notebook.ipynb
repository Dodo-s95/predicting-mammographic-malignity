{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_exam_Eduardo_Calò.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbQ2fGxH_qat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# general\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# pre-processing\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "\n",
        "# models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# tools\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "\n",
        "# parameter tuning\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnKUoennHoKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting random_state for reproducibility. The same will be used throughout the whole code\n",
        "\n",
        "random_state = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qOV-ZLPfIX0",
        "colab_type": "text"
      },
      "source": [
        "# Loading dataset, pre-processing and statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFlr9gR0Rf4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading data. Dataset description can be found on the report\n",
        "\n",
        "features = [\"BI-RADS\", \"Age\", \"Shape\", \"Margin\", \"Density\", \"Severity\"] # \"Severity\" will be our target (0 = benign, 1 = malignant)\n",
        "data = pd.read_csv(\"/content/drive/My Drive/ML exam/data/mammographic_masses.data\", names=features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RILq3HFTz_q",
        "colab_type": "code",
        "outputId": "00f08dc8-3013-45ac-caf7-d56c0ede81ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "data = data.iloc[:,1:6] # to discard \"BI-RADS\" which is a non-predictive attribute\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Shape</th>\n",
              "      <th>Margin</th>\n",
              "      <th>Density</th>\n",
              "      <th>Severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>58</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>74</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>47</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>957</th>\n",
              "      <td>56</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>959</th>\n",
              "      <td>66</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>960</th>\n",
              "      <td>62</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>961 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age Shape Margin Density  Severity\n",
              "0    67     3      5       3         1\n",
              "1    43     1      1       ?         1\n",
              "2    58     4      5       3         1\n",
              "3    28     1      1       3         0\n",
              "4    74     1      5       ?         1\n",
              "..   ..   ...    ...     ...       ...\n",
              "956  47     2      1       3         0\n",
              "957  56     4      5       3         1\n",
              "958  64     4      5       3         0\n",
              "959  66     4      5       3         1\n",
              "960  62     3      3       3         0\n",
              "\n",
              "[961 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHVddj4T0NDP",
        "colab_type": "text"
      },
      "source": [
        "From a first glance, it can be seen that **some values are missing** (\"?\"). This is a common problem in datasets. To solve this problem, first of all, I will replace them with a proper numPy NaN value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2bD-WJTSJuf",
        "colab_type": "code",
        "outputId": "18afc78f-656a-4cad-cb4b-e72a18f83bfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "data = data.replace(\"?\", np.nan)\n",
        "data.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Shape</th>\n",
              "      <th>Margin</th>\n",
              "      <th>Density</th>\n",
              "      <th>Severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>58</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>74</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>70</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Age Shape Margin Density  Severity\n",
              "0  67     3      5       3         1\n",
              "1  43     1      1     NaN         1\n",
              "2  58     4      5       3         1\n",
              "3  28     1      1       3         0\n",
              "4  74     1      5     NaN         1\n",
              "5  65     1    NaN       3         0\n",
              "6  70   NaN    NaN       3         0\n",
              "7  42     1    NaN       3         0\n",
              "8  57     1      5       3         1\n",
              "9  60   NaN      5       1         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKa2p9aL0qWM",
        "colab_type": "text"
      },
      "source": [
        "In this case, the best way to handle these missing values is to **drop all the instances containing NaN**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-djemWjrSLzT",
        "colab_type": "code",
        "outputId": "61f0098c-aee2-41ed-e376-61bca729896f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "data.dropna(inplace=True) # dropping NaN values\n",
        "data.reset_index(drop=True, inplace=True) # resetting indexes of dataframe for better handling later on\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Shape</th>\n",
              "      <th>Margin</th>\n",
              "      <th>Density</th>\n",
              "      <th>Severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>76</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>47</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>56</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>66</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830</th>\n",
              "      <td>62</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>831 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age Shape Margin Density  Severity\n",
              "0    67     3      5       3         1\n",
              "1    58     4      5       3         1\n",
              "2    28     1      1       3         0\n",
              "3    57     1      5       3         1\n",
              "4    76     1      4       3         1\n",
              "..   ..   ...    ...     ...       ...\n",
              "826  47     2      1       3         0\n",
              "827  56     4      5       3         1\n",
              "828  64     4      5       3         0\n",
              "829  66     4      5       3         1\n",
              "830  62     3      3       3         0\n",
              "\n",
              "[831 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGOop_fl1BDn",
        "colab_type": "text"
      },
      "source": [
        "After removal, from the original 961 instances, we are now down to 831."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcOwkABVUVxv",
        "colab_type": "code",
        "outputId": "d723913e-2aa5-46d5-9d13-b8f54d243456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "# a first look at the statistics\n",
        "\n",
        "data.describe(include=\"all\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Shape</th>\n",
              "      <th>Margin</th>\n",
              "      <th>Density</th>\n",
              "      <th>Severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>831</td>\n",
              "      <td>831</td>\n",
              "      <td>831</td>\n",
              "      <td>831</td>\n",
              "      <td>831.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>72</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>67</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>30</td>\n",
              "      <td>380</td>\n",
              "      <td>320</td>\n",
              "      <td>756</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.484958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Age Shape Margin Density    Severity\n",
              "count   831   831    831     831  831.000000\n",
              "unique   72     4      5       4         NaN\n",
              "top      67     4      1       3         NaN\n",
              "freq     30   380    320     756         NaN\n",
              "mean    NaN   NaN    NaN     NaN    0.484958\n",
              "std     NaN   NaN    NaN     NaN    0.500075\n",
              "min     NaN   NaN    NaN     NaN    0.000000\n",
              "25%     NaN   NaN    NaN     NaN    0.000000\n",
              "50%     NaN   NaN    NaN     NaN    0.000000\n",
              "75%     NaN   NaN    NaN     NaN    1.000000\n",
              "max     NaN   NaN    NaN     NaN    1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmwMF-rj1bTD",
        "colab_type": "text"
      },
      "source": [
        "From the above output we can see bizarre NaN values, instead of expected numerical values. The problem may be that some of the **values are not encoded as integers**, but as strings, so that proper statistics are not shown. To check this, I will apply a filter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAvvV0ObUYtE",
        "colab_type": "code",
        "outputId": "655b9449-16d0-43e5-d9cf-ed4fecb9d1ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "data.applymap(np.isreal)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Shape</th>\n",
              "      <th>Margin</th>\n",
              "      <th>Density</th>\n",
              "      <th>Severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>831 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Age  Shape  Margin  Density  Severity\n",
              "0    False  False   False    False      True\n",
              "1    False  False   False    False      True\n",
              "2    False  False   False    False      True\n",
              "3    False  False   False    False      True\n",
              "4    False  False   False    False      True\n",
              "..     ...    ...     ...      ...       ...\n",
              "826  False  False   False    False      True\n",
              "827  False  False   False    False      True\n",
              "828  False  False   False    False      True\n",
              "829  False  False   False    False      True\n",
              "830  False  False   False    False      True\n",
              "\n",
              "[831 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYxcQMLz2I2e",
        "colab_type": "text"
      },
      "source": [
        "As expected, probably none of them are encoded as integers (\"Severity\" column excluded). So in this step, I am going to **cast all the values into integers** to let them be properly handled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gIr3tGMVwqs",
        "colab_type": "code",
        "outputId": "3925e6cc-279d-44d4-87f6-7cbe040677ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "for feat in features[1:5]:\n",
        "    data[feat] = data[feat].apply(lambda x: int(x))\n",
        "\n",
        "data.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Shape</th>\n",
              "      <th>Margin</th>\n",
              "      <th>Density</th>\n",
              "      <th>Severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>76</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>36</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>52</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age  Shape  Margin  Density  Severity\n",
              "0   67      3       5        3         1\n",
              "1   58      4       5        3         1\n",
              "2   28      1       1        3         0\n",
              "3   57      1       5        3         1\n",
              "4   76      1       4        3         1\n",
              "5   42      2       1        3         1\n",
              "6   36      3       1        2         0\n",
              "7   60      2       1        2         0\n",
              "8   54      1       1        3         0\n",
              "9   52      3       4        3         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVnmUyGB2f0n",
        "colab_type": "text"
      },
      "source": [
        "Now all the values are integers and we can have a good account on the statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE3DcnohflXY",
        "colab_type": "code",
        "outputId": "16bfeded-ae30-49d5-9aee-9970a52e9f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Shape</th>\n",
              "      <th>Margin</th>\n",
              "      <th>Density</th>\n",
              "      <th>Severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>831.000000</td>\n",
              "      <td>831.000000</td>\n",
              "      <td>831.000000</td>\n",
              "      <td>831.000000</td>\n",
              "      <td>831.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>55.777377</td>\n",
              "      <td>2.783394</td>\n",
              "      <td>2.814681</td>\n",
              "      <td>2.915764</td>\n",
              "      <td>0.484958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14.663528</td>\n",
              "      <td>1.242331</td>\n",
              "      <td>1.566771</td>\n",
              "      <td>0.350737</td>\n",
              "      <td>0.500075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>46.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>57.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>66.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>96.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Age       Shape      Margin     Density    Severity\n",
              "count  831.000000  831.000000  831.000000  831.000000  831.000000\n",
              "mean    55.777377    2.783394    2.814681    2.915764    0.484958\n",
              "std     14.663528    1.242331    1.566771    0.350737    0.500075\n",
              "min     18.000000    1.000000    1.000000    1.000000    0.000000\n",
              "25%     46.000000    2.000000    1.000000    3.000000    0.000000\n",
              "50%     57.000000    3.000000    3.000000    3.000000    0.000000\n",
              "75%     66.000000    4.000000    4.000000    3.000000    1.000000\n",
              "max     96.000000    4.000000    5.000000    4.000000    1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBgE-pYc2vea",
        "colab_type": "text"
      },
      "source": [
        "The above general statistics alone are not that informative. So, next step is **plotting the histograms** for all the features to check if there are anomalies, outliers or fairness issues that could influence the learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w925e9YXfn5X",
        "colab_type": "code",
        "outputId": "8304003d-2f4a-4486-dc5c-b9b0476552da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "df_ben = data.loc[data[\"Severity\"] == 0]\n",
        "df_mal = data.loc[data[\"Severity\"] == 1]\n",
        "\n",
        "fig = plt.figure(1, figsize=(10.0,10.0))\n",
        "\n",
        "feats = {1:\"Age\", 2:\"Shape\", 3:\"Margin\", 4:\"Density\"}\n",
        "\n",
        "for k,v in feats.items():\n",
        "    chart = fig.add_subplot(2,2,k)\n",
        "    chart.title.set_text(v)\n",
        "    chart.hist(df_ben[v], alpha=0.5, color='red', label='benign', rwidth=0.6)\n",
        "    chart.hist(df_mal[v], alpha=0.5, color='blue', label='malignant', rwidth=0.6)\n",
        "    if v in (\"Shape\", \"Density\"):\n",
        "        chart.legend(loc='upper left')\n",
        "    else:\n",
        "        chart.legend(loc='upper right')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbh4zy367aQC",
        "colab_type": "code",
        "outputId": "f0da8e66-696a-4af5-d912-d4224496a176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# counting exact \"Severity\" instances\n",
        "\n",
        "Counter(data[\"Severity\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 428, 1: 403})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8vE9Zzp3TWK",
        "colab_type": "text"
      },
      "source": [
        "From the statistics above, we can notice several things:\n",
        "\n",
        "*   there are no anomalies, since all the values are within the features' expected ranges. In particular all the values for \"Age\" range from 18 to 96, those of \"Shape\" from 1 to 4, \"Margin\" from 1 to 5, \"Density\" from 1 to 4 and \"Severity\" contains only 0s and 1s.\n",
        "*   malignant cases range between around 25 and 96 years of \"Age\", with a shift towards older ages, and a peak around 65 years-old.\n",
        "*   \"Shape\" = 4 (*irregular*) is synonymous of malignity.\n",
        "*   \"Margin\" = 1 (*circumscribed*), on the contrary, is synonymous of benign.\n",
        "*   no clear-cut distinctions can be made within \"Density\" feature, since most of the values have value = 3 (*low*)\n",
        "*   there will be no fairness issues and algorithms will not be biased, since the distribution of our target \"Severity\" is pretty balanced with 428 benign instances and 403 malignant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNAXY3WkoKrS",
        "colab_type": "text"
      },
      "source": [
        "After some pre-processing and statistical analysis, we are now approaching the proper Machine Learning part. First of all, we can notice that there are several different data types in this dataset. \"Age\" is **quantitative**, while the 3 features \"Shape\", \"Margin\" and \"Density\" are **categorical**. In particular, \"Shape\" and \"Margin\" are **nominal**, while \"Density\" is **ordinal**. The main difference between ordinal and nominal feature is that the numbers used to encode ordinal variables have some sort of logical sense (they are used to keep some meaning in the data), while in nominal, numbers are just chosen arbitrarly. Keeping this mix of different variable types may lead to some bad effects on the equations used by the classifiers. To solve this problem, I will try to blend them. I will create dummy variables for the 2 nominal features using scikit-learn **OneHotEncoder**, while keeping \"Density\" untouched to preserve the ordinal relationship. Our target \"Severity\" is **dichotomous**, and so no processing is needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtY0kmXecn6M",
        "colab_type": "code",
        "outputId": "4f8535d5-9686-4ce2-bd0e-f523a7c0580f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "onehotencoder = OneHotEncoder()\n",
        "encod = pd.DataFrame(onehotencoder.fit_transform(data.iloc[:,1:3].to_numpy()).toarray())\n",
        "encod"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>831 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1    2    3    4    5    6    7    8\n",
              "0    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
              "1    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0\n",
              "2    1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
              "3    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
              "4    1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
              "..   ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "826  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
              "827  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0\n",
              "828  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0\n",
              "829  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0\n",
              "830  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
              "\n",
              "[831 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo60DpuuqwwM",
        "colab_type": "text"
      },
      "source": [
        "We can now compare the results of the encoding with the original data. Taking the first line of the 2 dataframes (you can see them right below this cell), it can be seen how the variables have been encoded. Let's take, for example the first feature \"Shape\": this feature originally ranges from 1 to 4, so in the encoded dataframe, the first 4 columns (0 to 3) will be attributed to feature \"Shape\". In particular, in the instance we selected, \"Shape\" gets value 3. This means that a value of 1 will be attributed to the 3rd column of the encoded dataframe, with the other values remaining 0. And that is exactly what happens! Then, \"Margin\" (ranging from 1 to 5) originally gets value 5 so the 9th column (4 attributed to \"Shape\" + 5 to \"Margin\") of the encoded dataframe will get the 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bEkkPHVqj7-",
        "colab_type": "code",
        "outputId": "80b69039-c397-40e7-809d-dc5d79ca3c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# first line of original dataframe\n",
        "\n",
        "data.iloc[:,1:3].head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Shape</th>\n",
              "      <th>Margin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Shape  Margin\n",
              "0      3       5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c40t6dfBqJsm",
        "colab_type": "code",
        "outputId": "1ece7da9-83b5-4b5f-e9e4-6ce90b458279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# first line of encoded dataframe\n",
        "\n",
        "encod.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4    5    6    7    8\n",
              "0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4eT7xFPtUlM",
        "colab_type": "text"
      },
      "source": [
        "Let's now concatenate the dataframes we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiiTzMLRiY26",
        "colab_type": "code",
        "outputId": "781288bd-2daa-4887-98a4-21ac8ae675de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "data_en = pd.concat([data[\"Age\"], encod, data[\"Density\"], data[\"Severity\"]], axis=1)\n",
        "data_en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>Density</th>\n",
              "      <th>Severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>57</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>56</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>66</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830</th>\n",
              "      <td>62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>831 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age    0    1    2    3    4    5    6    7    8  Density  Severity\n",
              "0     67  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0        3         1\n",
              "1     58  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0        3         1\n",
              "2     28  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0        3         0\n",
              "3     57  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0        3         1\n",
              "4     76  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0        3         1\n",
              "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...      ...       ...\n",
              "826   47  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0        3         0\n",
              "827   56  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0        3         1\n",
              "828   64  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0        3         0\n",
              "829   66  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0        3         1\n",
              "830   62  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0        3         0\n",
              "\n",
              "[831 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32Jw8x4v5N_k",
        "colab_type": "text"
      },
      "source": [
        "Another issue to solve before approaching the Machine Learning part is the imbalance due to the fact that data are not on the same scale (for instance, \"Age\" ranges from 18 to 96, \"Density\" from 1 to 4, while the other features are now binary). Since this problem may lead to inaccurate predictions, I will perform **feature scaling**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykTfyV_H75bm",
        "colab_type": "code",
        "outputId": "d6af173e-2243-4f5f-86e0-7931dd2a17ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "data_sc = pd.DataFrame(MinMaxScaler().fit_transform(data_en))\n",
        "data_sc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.628205</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.512821</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.128205</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.743590</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>0.371795</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>0.487179</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>0.589744</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830</th>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>831 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0    1    2    3    4    5    6    7    8    9        10   11\n",
              "0    0.628205  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.666667  1.0\n",
              "1    0.512821  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.666667  1.0\n",
              "2    0.128205  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.666667  0.0\n",
              "3    0.500000  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.666667  1.0\n",
              "4    0.743590  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.666667  1.0\n",
              "..        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...  ...\n",
              "826  0.371795  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.666667  0.0\n",
              "827  0.487179  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.666667  1.0\n",
              "828  0.589744  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.666667  0.0\n",
              "829  0.615385  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.666667  1.0\n",
              "830  0.564103  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.666667  0.0\n",
              "\n",
              "[831 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH0Ahru5988h",
        "colab_type": "text"
      },
      "source": [
        "Next step is to **shuffle** and to **split** data into features **X** and target **y**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi23zd-p6UpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_sc = data_sc.sample(frac=1, random_state=random_state)\n",
        "\n",
        "X = data_sc.iloc[:,0:11]\n",
        "y = data_sc.iloc[:, 11]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SUt_8p0-bkI",
        "colab_type": "code",
        "outputId": "386f58c2-72a4-418b-f252-04d030766d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>0.038462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>818</th>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>0.576923</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>0.615385</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0.038462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>0.320513</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>0.346154</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.641026</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>831 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0    1    2    3    4    5    6    7    8    9        10\n",
              "610  0.038462  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.666667\n",
              "818  0.461538  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.666667\n",
              "290  0.717949  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.666667\n",
              "559  0.076923  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.666667\n",
              "168  0.576923  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.666667\n",
              "..        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...\n",
              "71   0.615385  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.666667\n",
              "106  0.038462  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.666667\n",
              "270  0.320513  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.666667\n",
              "435  0.346154  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.666667\n",
              "102  0.641026  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.666667\n",
              "\n",
              "[831 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooD7WYSMmL4N",
        "colab_type": "code",
        "outputId": "e4cf308f-acb5-4c92-9130-a53a6eb38dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "610    0.0\n",
              "818    1.0\n",
              "290    1.0\n",
              "559    0.0\n",
              "168    0.0\n",
              "      ... \n",
              "71     0.0\n",
              "106    0.0\n",
              "270    0.0\n",
              "435    1.0\n",
              "102    1.0\n",
              "Name: 11, Length: 831, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5pG9OhZfdsV",
        "colab_type": "text"
      },
      "source": [
        "# Algorithm selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XftKEx5VBXqP",
        "colab_type": "text"
      },
      "source": [
        "As far as this problem is concerned, we are in the realm of **Supervised Machine Learning**, dealing with a **binary classification**. This means that all the input data are labeled with a category and that the classifiers, analyzing these data, will have to learn a function which can be used for mapping new unseen examples. In our specific case, inputs are vectors of 11 dimensions and the output is dichotomous or binary (0=benign or 1=malignant). Therefore, I decided to try out **all major ML algorithms for classification** using their default parameters, in order to set a **baseline** and check which one has more potential to be more accurate with some **fine tuning over parameters**. I will split the whole dataset in **train and test set**. The train set will be used for baseline and parameters tuning, and these results will be compared. I will keep the test set only for the very end to check how the best classifier performs on new unseen data. For the baseline and parameters tuning, I will use **5-fold cross validation**. This means that the data used will be split into 5 folds and each algorithm will run 5 times, each time picking one fold as test set, and the rest as training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOqUsMHVOdA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# splitting dataset\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False) # already shuffled before. 250 test samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiBzDGVoYIoS",
        "colab_type": "code",
        "outputId": "f549a061-e532-4b0b-ab75-496bd8bceb09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "# baseline\n",
        "\n",
        "models = [LogisticRegression(random_state=random_state),\n",
        "          MultinomialNB(),\n",
        "          KNeighborsClassifier(),\n",
        "          SVC(random_state=random_state),\n",
        "          LinearSVC(random_state=random_state),\n",
        "          DecisionTreeClassifier(random_state=random_state),\n",
        "          RandomForestClassifier(random_state=random_state),\n",
        "          GradientBoostingClassifier(random_state=random_state),\n",
        "          XGBClassifier(random_state=random_state)]\n",
        "\n",
        "model = []\n",
        "mean = []\n",
        "std = []\n",
        "mins = []\n",
        "maxs = []\n",
        "\n",
        "for clf in models:\n",
        "    cross = cross_val_score(clf, X_train, y_train, cv=5) # 5-fold on train set\n",
        "    model.append(type(clf).__name__)\n",
        "    mean.append(cross.mean())\n",
        "    std.append(cross.std())\n",
        "    mins.append(min(cross))\n",
        "    maxs.append(max(cross))\n",
        "\n",
        "# creating dataframe for better fruition of results\n",
        "\n",
        "result = pd.DataFrame({\"Model\":model, \"Acc. mean\":mean, \"STD\":std, \"min\":mins, \"max\":maxs})\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Acc. mean</th>\n",
              "      <th>STD</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.795181</td>\n",
              "      <td>0.041299</td>\n",
              "      <td>0.724138</td>\n",
              "      <td>0.853448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>0.789979</td>\n",
              "      <td>0.035780</td>\n",
              "      <td>0.741379</td>\n",
              "      <td>0.844828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.772782</td>\n",
              "      <td>0.028287</td>\n",
              "      <td>0.724138</td>\n",
              "      <td>0.801724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.786561</td>\n",
              "      <td>0.038002</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.853448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>0.791733</td>\n",
              "      <td>0.041328</td>\n",
              "      <td>0.724138</td>\n",
              "      <td>0.853448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.703876</td>\n",
              "      <td>0.029845</td>\n",
              "      <td>0.672414</td>\n",
              "      <td>0.752137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.738255</td>\n",
              "      <td>0.048825</td>\n",
              "      <td>0.681034</td>\n",
              "      <td>0.811966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.755541</td>\n",
              "      <td>0.031484</td>\n",
              "      <td>0.715517</td>\n",
              "      <td>0.793103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.772738</td>\n",
              "      <td>0.032458</td>\n",
              "      <td>0.715517</td>\n",
              "      <td>0.811966</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Model  Acc. mean       STD       min       max\n",
              "0          LogisticRegression   0.795181  0.041299  0.724138  0.853448\n",
              "1               MultinomialNB   0.789979  0.035780  0.741379  0.844828\n",
              "2        KNeighborsClassifier   0.772782  0.028287  0.724138  0.801724\n",
              "3                         SVC   0.786561  0.038002  0.750000  0.853448\n",
              "4                   LinearSVC   0.791733  0.041328  0.724138  0.853448\n",
              "5      DecisionTreeClassifier   0.703876  0.029845  0.672414  0.752137\n",
              "6      RandomForestClassifier   0.738255  0.048825  0.681034  0.811966\n",
              "7  GradientBoostingClassifier   0.755541  0.031484  0.715517  0.793103\n",
              "8               XGBClassifier   0.772738  0.032458  0.715517  0.811966"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbVrVKUQ4I7Q",
        "colab_type": "text"
      },
      "source": [
        "From the above estimations, we can see a general positive trend. However, some of classifiers slightly outperform others. The ones which seem to behave more or less equivalently are worth exploring. So, I will pick the ones which have the mean accuracy value around 80% (**LogisticRegression** and **LinearSVC**) and try to **tune their parameters** to hopefully achieve better performance. Most notably, all tree-like classifiers behave generally worse compared to other types of classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LNTs8EazeHu",
        "colab_type": "text"
      },
      "source": [
        "I will now give a very quick overview on these 2 classifiers.\n",
        "- **Logistic Regression** is a simple, but effective algorithm. It indeed frequently outperforms much more complex classifiers. It is appropriate to solve (binary) classification problems like ours. It basically analiyzes the relationship between dependent and independent variables and estimates the probability of an event to occur, using a logstic sigmoid function.\n",
        "- **LinearSVC** is a Support Vector Machines (SVM) type algorithm. These type of classifiers try to find the optimal hyperplane that distinctly classifies the data points in an n-dimensional space. In a two dimensional space, for example, a hyperplane is a line that optimally divides the data points into two different classes. The further from the hyperplane our data points lie, the more confident we are that they have been correctly classified. The goal is to choose a hyperplane with the greatest possible margin (distance between the hyperplane and the nearest data point from either set) between the hyperplane and any point within the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVfgUidgpWrg",
        "colab_type": "text"
      },
      "source": [
        "I will use Pipeline and GridSearch from scikit-learn to help me find the **best combination of parameters**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snCcGI7EXHMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LogisticRegression parameters\n",
        "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "\n",
        "# LinearSVC parameters\n",
        "loss = ['hinge', 'squared_hinge']\n",
        "\n",
        "# shared parameters\n",
        "penalty = ['l1', 'l2', 'elasticnet']\n",
        "dual = [True, False]\n",
        "tol = list(np.arange(0.0001,0.001,0.0001))\n",
        "C = np.logspace(-4, 4, 20)\n",
        "\n",
        "# creating a Pipeline object, a parameters grid and a GridSearch object\n",
        "pipe = Pipeline([('classifier', LogisticRegression())]) # dummy needed to create Pipeline. The actual classifiers to compare are in the grid\n",
        "\n",
        "param_grid = [\n",
        "    {'classifier' : [LogisticRegression(max_iter=10000, random_state=random_state, n_jobs=-1)],\n",
        "     'classifier__penalty' : penalty,\n",
        "     'classifier__dual' : dual,\n",
        "     'classifier__tol' : tol,\n",
        "     'classifier__C' : C,\n",
        "     'classifier__solver' : solver},\n",
        "     {'classifier' : [LinearSVC(max_iter=10000, random_state=random_state)],\n",
        "     'classifier__penalty' : penalty,\n",
        "     'classifier__dual' : dual,\n",
        "     'classifier__tol' : tol,\n",
        "     'classifier__C' : C,\n",
        "     'classifier__loss' : loss}]\n",
        "\n",
        "clf = GridSearchCV(pipe, param_grid=param_grid, n_jobs=-1, cv=5) # 5-folds to tune parameters using train data\n",
        "best_clf = clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG5CrmCmQq9C",
        "colab_type": "text"
      },
      "source": [
        "The **best model** with the best parameters has finally been found!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV7J14sVCF38",
        "colab_type": "code",
        "outputId": "1094d968-6e02-463c-9210-ef042ea16945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "best_clf.best_estimator_['classifier']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=10000, multi_class='auto', n_jobs=-1, penalty='l1',\n",
              "                   random_state=42, solver='saga', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "163Z46JySaHd",
        "colab_type": "code",
        "outputId": "dd2df2a1-6319-4a92-d03f-a4a8c5ddb6b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "best_clf.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7968759210138521"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-aV_EJvX9dg",
        "colab_type": "text"
      },
      "source": [
        "The best classifier is a **LogisticRegression** model. The *best_score* reported above corresponds to the mean of accuracies of the 5 folds used by GridSearch on train data. So, this result can be compared to the accuracy mean achieved before with the baseline. This Logistic Regression model achieves a slightly higher value of mean accuracy with **0.796876** compared to the 0.795181 of the baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o19hJ7sfpi_",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDu0Cii4onMk",
        "colab_type": "text"
      },
      "source": [
        "I will now use this best classifier to make predictions over the new unseen data of the test set. I will then calculate **precision**, **recall**, **f1-score** and **confusion matrix**, to have a complete account on true positive, true negatives, false positives, and false negatives. In medical field, these metrics are all useful, since these cases will have to be treated differently. Our problem, which is avoiding unnecessary biopsies predicting the malignity of the mammographic masses, is no different."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CztVvkceRpsq",
        "colab_type": "code",
        "outputId": "3f002e69-9eb6-443f-81e1-7e78618900f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "# predicting over test set\n",
        "y_pred = best_clf.predict(X_test)\n",
        "\n",
        "# plotting confusion matrix\n",
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "matrix = sns.heatmap(conf_mat, annot=True, fmt='d', linewidths=.5, cmap='coolwarm')\n",
        "matrix.set(xlabel='predicted', ylabel='actual')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(33.0, 0.5, 'actual'), Text(0.5, 15.0, 'predicted')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEGCAYAAABFBX+4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAaQUlEQVR4nO3de5RV5Znn8e+P4iIISgFS4WakFW9Jj2hs73fSxktUdDlONFGSoad60nbUaEaMujra5qKJ3eYyk0wqaqc6UaOxNaAmJjRREAdRRBQVFETRIgUoFEgAEaqe+WNv9EiK4tTmnDpnF7/PWu86+7xnn72fcpUPb737vSgiMDOz/OhR6QDMzKxznLjNzHLGidvMLGecuM3McsaJ28wsZ3pWOoAOeLiLmRVLO3uBR3odUHTOOXPzKzt9v51RzYmb2UcfWekQrIocOWs2ACecO7PCkVg1mfHgcZUOoctVdeI2M+sq6lXRRnSnOHGbmQE1fWsqHULRnLjNzIAePd3iNjPLFXeVmJnljFvcZmY54xa3mVnOuMVtZpYzNb3zM5HcidvMDFAPt7jNzHJFNW5xm5nlSo8at7jNzHLFXSVmZjnjh5NmZjmjHk7cZma5kqeukvz8E2NmVkY9alR02RFJd0paKenFgrpBkqZKWpS+1qb1kvRDSYslvSDpsB3GulM/qZlZN6EeKroU4efAadvUXQNMi4gxwLT0PcDpwJi01AM/2dHFnbjNzEj6uIstOxIRM4DV21SfAzSmx43A+IL6f4/EU8BAScM6ur77uM3MgJpexbdjJdWTtI63aoiIhh18rS4imtPj5UBdejwCeKvgvKa0rpntcOI2M6NzDyfTJL2jRN3R90NS5g3RnbjNzOiS4YArJA2LiOa0K2RlWr8MGFVw3si0brvcx21mRskfTrZnCjAhPZ4ATC6ovyQdXXIUsLagS6VdbnGbmVHacdyS7gFOAoZIagK+AdwM3CdpIrAUuCA9/bfAGcBiYAPwpR1d34nbzAzo0bN0u7xHxIXb+WhcO+cGcGlnru/EbWaGVwc0M8udPE15d+I2M8OLTJmZ5Y5b3GZmOePEbWaWM6UcVVJuTtxmZriP28wsf+SuEjOzXHEft5lZzrirxMwsZ9ziNjPLGY8qMTPLGbe4zczyxn3cZmb5ohwNB8zPPzFmZmVUyl3eJV0u6UVJL0m6Iq0bJGmqpEXpa23WWJ24zcwA9awpunR4HemTwP8AjgAOAT4raT/gGmBaRIwBpqXvM3HiNjOjpHtOHgTMjogNEbEFmA6cB5wDNKbnNALjs8bqxG1mBkg9OlFUL2lOQakvuNSLwPGSBkvqR7Kf5CigrmAT4OVAXdZY/XDSzAygE8MBI6IBaNjOZwsk3QL8AVgPzANatzknJEXmULN+0cysOynlw8mIuCMiPhURJwAtwKvACknDANLXlVljdeI2M6OkfdxIGpq+7k3Sv303MAWYkJ4yAZicNVZ3lZiZAaop6ZT3/5A0GNgMXBoRayTdDNwnaSKwFLgg68WduM3MoKQzJyPi+HbqVgHjSnF9J24zM/I1c9KJuwqMvu56ao85ls0tLcz/wkUA1OyxB2Nu+iZ9hg1nU/OfWHT9dbSuW0ft8Scwsr6eaAuitZWl37+NP7/wfIV/Aiu3oYN7c+3l+zNoYG8igoemruD+h//EgP49ueGqAxg2dDeaV77HN25dyJ/Xt+74gvaXcrRWSX4i7cbeeeRhFn71io/UDb/4EtbOmcPzF5zP2jlzGH7xJQCsnfMM8y/+Ai9OuJgl3/omf3XttZUI2bpYa1vw45+/ziWXzeV/TnqBc08fxsdH9uXz541k7vy1XHTps8ydv5YvnDeq0qHmVikfTpZb2RK3pAMlTZL0w7RMknRQue6XZ+vmzWPLu+9+pK72+BN457ePAPDObx+h9oQTAWjbuPGDc2r67gaReSio5ciqls28umQ9ABvfa2Vp0wb2GtyH444YxKOPrQDg0cdWcNyRgyoZZr6pR/GlwsrSVSJpEnAh8Cvg6bR6JHCPpF9FxM3luG930mvQIDavWgXA5lWr6DXow/8ha088kVFf/gd61dbyylVXVipEq5CP7dWHMaN35+VX11E7sDerWjYDSXKvHdi7wtHlV4lHlZRVufq4JwKfiIjNhZWS/hV4CWg3cafTRusBfvrTn3JImYLLpYKWdcv06bRMn86AsWMZWf/3LLzsKxUMzLpS3916cNOkg/jRna+zYWM7fdn+Ayy7KugCKVa52vxtwPB26oeln7UrIhoi4vCIOLy+vn57p+0SNq9eTa/BgwHoNXgwm1ta/uKcdfPm0Wf4CHruuWdXh2cVUFMjbrr6IKbOWMmMp5K/xlrWvM/g2l4ADK7tRcva9ysZYq6VcuZkuZUrgiuAaZJ+J6khLY+SLGV4eZnu2a20zHyCIWecCcCQM86k5YkZAPQZOfKDc/rtfwA9evdiy9q1FYnRutakS8ewtGkD90350wd1Tz6zmtNOTtYqOu3kOmY+vbpS4eWfVHypsLJ0lUTEo5L2J1mPdkRavQx4JiI8Vmkb+954E3scdhg9Bw7k0MkP0XR7A83/3sh+3/o2Q886m03Lm1l0/XUADDrpZIacfgaxZQttmzax6PrrKxy9dYW/PmgPTjt5KK+9sZ47/nUsAD/75VLueqCJG792IGeOq2P525v4xq0LKxxpjlVBS7pYiuodlRCzjz6y0jFYFTly1mwATjh3ZoUjsWoy48HjAHa6GbzxF98sOhn2vfj6ija7PQHHzAyqYphfsZy4zcwgV6NKnLjNzEh2wMkLJ24zM3CL28wsd9ziNjPLmRxNec/PPzFmZuVUwkWmJH1V0kuSXpR0j6TdJI2WNFvSYkn3Ssq8sIwTt5kZJH3cxZYOSBoBXAYcHhGfBGqAzwG3ALdFxH4kGwhPzBxq1i+amXUrpV3WtSfQV1JPoB/QDJwC3J9+3giMzxqqE7eZGXRqrRJJ9ZLmFJQPVsWLiGXArcCbJAl7LfAssCYitqSnNfHhciCd5oeTZmbQqbVKIqIBaGjvM0m1wDnAaGAN8GvgtBJE+AEnbjMzgB4lG1XyaeD1iHgbQNIDwLHAQEk901b3SJKF9zJxV4mZGSQt7mJLx94EjpLUT8nW8eOAl4HHgPPTcyYAkzOHmvWLZmbdSonW446I2SQPIecC80nybAMwCbhS0mJgMHBH1lDdVWJmBiWdORkR3wC+sU31EpI9CnaaE7eZGVTFzjbFcuI2MwMiR1PenbjNzMCLTJmZ5Y4Tt5lZvoT7uM3McsYtbjOznHGL28wsXzyqxMwsb9xVYmaWL+HEbWaWM+7jNjPLF7e4zczypnTrcZedE7eZGZ6AY2aWPznqKslPpGZmZRSo6NIRSQdImldQ3pV0haRBkqZKWpS+1maN1YnbzIzk4WSxpcPrRLwSEWMjYizwKWAD8CBwDTAtIsYA09L3mThxm5lB0lVSbCneOOC1iFhKsvN7Y1rfCIzPGqr7uM3MgLZOjCqRVA/UF1Q1RERDO6d+DrgnPa6LiOb0eDlQlyVOcOI2M0t0YlRJmqTbS9QFl1Nv4Gzg6+18PyRFZ0PcyonbzIyyTMA5HZgbESvS9yskDYuIZknDgJVZL+w+bjMzSjeqpMCFfNhNAjAFmJAeTwAmZ421wxa3pHVAe815kbT298h6YzOzalLKFrek3YG/Bf6+oPpm4D5JE4GlwAVZr99h4o6IAVkvbGaWKyWcORkR64HB29StIhllstM61cctaSiwW0Egb5YiCDOzSmtTN1urRNLZwL8Aw0k61D8OLAA+Ub7QzMy6Tp5WByw20puAo4BXI2I0SXP/qbJFZWbWxcrwcLJsik3cm9P+mR6SekTEY8DhZYzLzKxLlWrKe1coto97jaT+wAzgLkkrgfXlC8vMrGt1x2VdzwHeA74KfB7YE/jncgVlZtbVut3DyXRoy1aN2z3RzCynqqHvuljFjiopnIjTG+gFrPcEHDPrLqqh77pYxba4P5iII0kkXSdHlSsoM7OulqcWtyKyLVAl6bmIOLTE8RTKvHKWme1ydjrrvv7a4qJzzuh996toli+2q+S8grc9SIYCvleWiMzMKiBPLe5iR5WcVXC8BXiDpLukrI47a3q5b2E5MvOhEwF4pNcBFY7EqsmZm18pyXXacrRYarGJ+/aIeLKwQtKx7MR6smZm1SRylLiLjfRHRdaZmeVSnqa872g97qOBY4C9JF1Z8NEeQH5Gq5uZ7UA1JORi7ajF3RvoT5LgBxSUd4HzyxuamVnXKWWLW9JASfdLWihpgaSjJQ2SNFXSovS1NmusO9pIYTowXdLP0+3lzcy6pRK3uH8APBoR56ebBvcDrgWmRcTNkq4BrgEmZbl4sX3ct0sauPWNpFpJv89yQzOzatQWPYouHZG0J3ACcAdARLwfEWtIRuJtXTKkERifNdZiE/eQ9MakgbQAQ7Pe1Mys2pSwq2Q08Dbwb5Kek3R7ugdlXUQ0p+csB+qyxlps4m6TtPfWN5L2wTMbzawb6UzillQvaU5BqS+4VE/gMOAn6ezy9STdIh/eK5mynjmHFjuO+zpgpqTpJFNLjwfqO/6KmVl+RBTfxx0RDUDDdj5uApoiYnb6/n6SxL1C0rCIaJY0jJ2YB1NUizsiHiWZ5v4KcA9wFbAx603NzKpNGyq6dCQilgNvSdo6xXcc8DIwBZiQ1k0AJmeNtdi1Sv4OuBwYCcwjWRlwFnBK1hubmVWTHT107KSvkOwW1htYAnyJpKF8n6SJwFLggqwXL7ar5HLgb4CnIuJkSQcC3856UzOzalPK4YARMY/29+UdV4rrF5u434uI9yQhqU9ELCz4M8DMLPc608ddacUm7qZ0HPdvgKmSWkia+mZm3UKeprwXuwPOuenhDZIeI9ks+NGyRWVm1sW6Y4v7A+k0eDOzbqWt0gF0QqcTt5lZd1TiUSVl5cRtZkY37yoxM+uOut3DSTOz7q4tR6svOXGbmeEWt5lZ7riP28wsZ1qduM3M8sUtbjOznAk/nDQzyxc/nDQzyxkPBzQzy5m2Nre4zcxyZUdbknWGpDeAdUArsCUiDpc0CLgX2Ad4A7ggIlqyXD8/q6qYmZVRRPGlSCdHxNiI2LoTzjXAtIgYA0xjm53fO8OJ28yMZDhgsSWjc4DG9LgRGJ/1Qk7cZmYkDyeLLZLqJc0pKPXbXC6AP0h6tuCzuohoTo+XA3VZY3Uft5kZnRvHHRENQEMHpxwXEcskDSXZ7nHhNt8PSZnHsThxm5lR2invEbEsfV0p6UHgCGCFpGER0SxpGLAy6/XdVWJmRukeTkraXdKArcfAqcCLwBRgQnraBGBy1ljd4jYzo6RT3uuAByVBkmPvjohHJT0D3CdpIrAUuCDrDZy4zcyAthJ1lUTEEuCQdupXAeNKcQ8nbjMzvMiUmVnutLZVOoLiOXGbmeH1uM3McsddJWZmOeNlXc3McsYtbjOznHHiNjPLGY8qMTPLmTYnbjOzfHFXiZlZzjhxW2Zfv2x/jvmbwbSs3cwl/zgHgP322Z2vXbo/fXfrwfKVm7jx1gVs2Nha4Uit3P7Lz77N0DNO4v2Vq5hx6FkA9Krdk0Pvvo1+Hx/BhqXLmHvhFWxZ8y499+jP2Mbv0Xfv4aimhiW33UlT4wMV/gnyJU/DAb2sa5X57bQVXHXD/I/UTbpsf/5v4xImfOVZZsx6h4vOG1Wh6KwrNTU+wNOf/buP1O17dT2r/jiLxw/+DKv+OIv9rk42V/n4lz/Pnxe8xhOfOoenPn0xB313EurVqxJh51ZEFF0qzYm7yjz/0lreXbf5I3Wjhvdj3otrAXhmXgsnHjOkEqFZF1s9cw6bV6/9SF3dWeNo+sVvAGj6xW+oO/vTyQcR9BywOwA1/Xdn8+q1xJYtXRpv3rW2Fl8qzYk7B15/cz3HHzUYgJOP3Yu6IX0qHJFVSp+6wWxa/jYAm5a/TZ+65PfijR/fRf8D92Xcm09wwnNTePnKb+Wr07YKlGGX97Lp8sQt6UsdfPbBBpwNDR1t57Zr+c4PX+HcM4Zzx22H0a9vDZu3VMFvjlWHNIvsdepxrH1+AdP2Pp4nDh/PJ37wTx+0wK04ndksuBiSaiQ9J+nh9P1oSbMlLZZ0r6TeWWOtRIv7xu19EBENEXF4RBxeX7/tpsm7rjebNnLlP81n4lfn8p8zVrJs+cZKh2QVsmnFKvp8bC8A+nxsLzatXA3AqAnnsfzBPwCw4bU32fBGE7sf+FcVizOPytDivhxYUPD+FuC2iNgPaAEmZo21LIlb0gvbKfPZiS3pd1UD90weMkkw4b/tzeTfNVc4IquUFQ//kZEXjwdg5MXjWfHQNAA2vtXMkFOOBqD30MH03380G5Y0VSzOPIq2KLrsiKSRwJnA7el7AacA96enNALjs8ZaruGAdcBnSP5VKSTg/5Xpnt3CDV87iLF/vScD9+jFA/92FHfc/Qb9dqvhvDOHAzB91js88p/LKxyldYWxv/gXBp94BL2H1HLK69NZ9M8/4rXvNnDYPd9n1JfOZ+Obf2LuhVcAsOhbP+aQO77D8c9NQYiF197K5lXb/u9nHenMlHdJ9UBht0BDRBT2734fuBoYkL4fDKyJiK1PjJuAEVljLVfifhjoHxHztv1A0uNlume3cMOtC9qt//VDy7o4Equ0eRdf1W797M988S/qNjWv5OkzMv/lbUBbJwZyp0m63Qdxkj4LrIyIZyWdVJroPqosiTsitvsbFBEXleOeZmY7o4SjRY4FzpZ0BrAbsAfwA2CgpJ5pq3skkLk15uGAZmaU7uFkRHw9IkZGxD7A54A/RsTngceA89PTJgCTs8bqxG1mBrRFFF0ymgRcKWkxSZ/3HVkv5LVKzMyAKMOyrhHxOPB4erwEOKIU13XiNjMDWlvzM7HNidvMDKpi8ahiOXGbmZGvZV2duM3MoKgZkdXCidvMjOpY9a9YTtxmZnRu5mSlOXGbmQFtHlViZpYvOzGxpss5cZuZ4eGAZma54z5uM7OcyVGD24nbzAygtTM7KVSYE7eZGZ6AY2aWO07cZmY5k6O87cRtZgb5anF7BxwzM5Jx3MWWjkjaTdLTkp6X9JKkG9P60ZJmS1os6V5JvbPG6sRtZkYyqqTYsgObgFMi4hBgLHCapKOAW4DbImI/oAXY7qbqO+LEbWZG0lVSbOnwOok/p297pSWAU4D70/pGYHzWWJ24zczoXOKWVC9pTkGpL7yWpBpJ84CVwFTgNWBNRGxJT2kCRmSN1Q8nzczo3CJTEdEANHTweSswVtJA4EHgwJ0OsIATt5kZ5RlVEhFrJD0GHA0MlNQzbXWPBJZlva67SszMKOmokr3SljaS+gJ/CywAHgPOT0+bAEzOGqtb3GZmQOuWkq1VMgxolFRD0ji+LyIelvQy8CtJ3wSeA+7IegMnbjMzSrced0S8ABzaTv0S4IhS3MOJ28wMiDavDmhmliveSMHMLGe8dZmZWc60le7hZNk5cZuZAW3hxG1mlit5WtbVidvMDCduM7Pc8cNJM7OcafM4bjOzfGlrba10CEVz4jYzw33cZma548RtZpYzHsdtZpYzbnGbmeVMnlYH9A44ZmYko0qKLR2RNErSY5JelvSSpMvT+kGSpkpalL7WZo3VidvMjGRZ12LLDmwBroqIg4GjgEslHQxcA0yLiDHAtPR9Ju4qMTOjdF0lEdEMNKfH6yQtAEYA5wAnpac1Ao8Dk7Lcw4nbzIzOPZyUVA/UF1Q1RERDO+ftQ7KN2WygLk3qAMuBuqyxOnGbmQHRieGAaZL+i0RdSFJ/4D+AKyLiXUmF3w9JmYexVHXinvnQiZUOwarQmZtfqXQI1g21bSndlHdJvUiS9l0R8UBavULSsIholjQMWJn5+nlaEWtXJam+vT/DbNfm34vqpKRp3QisjogrCuq/B6yKiJslXQMMioirM93Dibv6SZoTEYdXOg6rLv69qE6SjgOeAOYDW/tfriXp574P2BtYClwQEauz3KOqu0rMzPImImYC2s7H40pxD4/jNjPLGSfufHA/prXHvxe7KPdxm5nljFvcZmY548RtZpYzTtxVTtJpkl6RtDgd+2m7OEl3Slop6cVKx2KV4cRdxSTVAP8HOB04GLgwXWXMdm0/B06rdBBWOU7c1e0IYHFELImI94FfkawwZruwiJgBZJq4Yd2DE3d1GwG8VfC+Ka0zs12YE7eZWc44cVe3ZcCogvcj0zoz24U5cVe3Z4AxkkZL6g18DphS4ZjMrMKcuKtYRGwB/hH4PbAAuC8iXqpsVFZpku4BZgEHSGqSNLHSMVnX8pR3M7OccYvbzCxnnLjNzHLGidvMLGecuM3McsaJ28wsZ5y4rapJOknSw+nx2R2tkChpoKR/yHCPGyR9bWfiNOtKTtxWEenKh50SEVMi4uYOThkIdDpxm+WNE7eVnKR9JC2UdJekBZLul9RP0huSbpE0F/ivkk6VNEvSXEm/ltQ//f5p6ffnAucVXPeLkv53elwn6UFJz6flGOBmYF9J8yR9Lz3vf0l6RtILkm4suNZ1kl6VNBM4oAv/85jttJ6VDsC6rQOAiRHxpKQ7+bAlvCoiDpM0BHgA+HRErJc0CbhS0neBnwGnAIuBe7dz/R8C0yPi3LT13h+4BvhkRIwFkHQqMIZkeVwBUySdAKwnWT5gLMn/A3OBZ0v885uVjRO3lctbEfFkevxL4LL0eGsiPopkc4gnJQH0JpnGfSDwekQsApD0S6C+neufAlwCEBGtwFpJtducc2pankvf9ydJ5AOAByNiQ3oPr/9iueLEbeWy7VoKW9+vT18FTI2ICwtPkjS2hDEI+E5E/HSbe1xRwnuYdTn3cVu57C3p6PT4ImDmNp8/BRwraT8ASbtL2h9YCOwjad/0vAtp3zTgy+l3ayTtCawjaU1v9Xvgvxf0nY+QNBSYAYyX1FfSAOCsnflBzbqaE7eVyyvApZIWALXATwo/jIi3gS8C90h6gbSbJCLeI+kaeSR9OLlyO9e/HDhZ0nyS/umDI2IVSdfLi5K+FxF/AO4GZqXn3Q8MiIi5JF02zwO/I1k+1yw3vDqglZykfYCHI+KTFQ7FrFtyi9vMLGfc4jYzyxm3uM3McsaJ28wsZ5y4zcxyxonbzCxnnLjNzHLm/wMXS/T+BFDScQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua8_iUYUhnuj",
        "colab_type": "code",
        "outputId": "a971d4ee-55a9-4dc2-defc-9f671aaeb1c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# prining out all the metrics\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.84      0.84       123\n",
            "         1.0       0.84      0.85      0.85       127\n",
            "\n",
            "    accuracy                           0.84       250\n",
            "   macro avg       0.84      0.84      0.84       250\n",
            "weighted avg       0.84      0.84      0.84       250\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOHOV9DPtbLY",
        "colab_type": "text"
      },
      "source": [
        "The problem we had to solve was to **reduce** the amount of unnecessary prescribed **biopsies**, due to inaccurate human interpretation of mammographic results (around 70% of biopsies turn out to be unnecessary). This means that **false positives** (detection of malignity when it is not present) are numerous. On new unseen data, our model achieves only **8%** (20/250) of false positives. This means that it rarely would \"suggest\" a biopsy when indeed it is not necessary. Unfortunately, it also predicts 7.6% of false negatives (19/250), where a mass is considered healthy while being indeed malignant. However, this model is really efficient in predicting **true positives** and **true negatives**, with precisions, recalls and f1-score (their harmonic mean) really high. All in all, our target has been centered, achieving a **drastic reduction** of the amount of unnecessary biopsies."
      ]
    }
  ]
}